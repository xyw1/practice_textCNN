{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dive into Deep Learning \n",
    "\n",
    "Chapter 10\n",
    "\n",
    "Section 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2lzh as d2l\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon import data as gdata, loss as gloss, nn \n",
    "from mxnet import gluon, init, nd\n",
    "from mxnet.contrib import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "#d2l.download_imdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = d2l.read_imdb('train'),d2l.read_imdb('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['this movie is to halloween what the hilarious \"christmas story\" is to christmas: both are relatively low-budget, no-big-name-stars type films...and both are two of the absolute greatest and funniest movies available, both seasonal classics!!! \"spaced invaders\" comes galloping out right from the start with warmth and humor and a superb cast of characters...all five goofy martians, klembecker the realtor, russell the deputy, vern at the \"fuel dispensing depot\" and so many more! you just have to see this movie to believe it, and, like \"christmas story\", it just keeps getting better and better with each viewing, and you pick up on fun little things each time!! most definitely a ten!!!',\n",
       "  1],\n",
       " [\"i've said this in other reviews, without a story, you can give the audience all the smoke and mirrors you want, still no one will give a damn.<br /><br />the director seems to have a great eye for 30s art deco (which i love), and i think the idea of using all digital backgrounds and such could indeed be the wave of the future in movie making. however, it's obvious the director got so interested in the digital rendering of his movie, he forgot to film many scenes which would have enormously helped this surprisingly thinned-plotted film. (spoiler) for crying out loud, they forgot to have a villain in this thing! ok they have one, but he's been dead for 20 years by the time the movie takes place. conran misses the point of having a villain. as far as action goes, well let's see, sky captain (law) shoots down one robot, two or three of the flapping wing airplanes (before dex (ribisi) tells him to stop shooting them down!!!), and a couple robots, but mostly spends his time looking dashing and getting others to fight his battles for him. paltrow as polly or peggy or punky or whatever is totally wasted in this movie (the reviewer who comments on hers and law's lack of chemistry is so right) and i for one got a little sick of seeing repeated shots of the top of her camera, showing she only has two shots left, both of which she wastes subsequently in the movie, one uncomically, one quite funny, although i saw it coming from 70 years away. no one except law and paltrow have any significant time on screen, and that's the movie's real flaw. an audience doesn't identify with robots, they need a hero to root for, and a visible, despicable villain to hate. without that, plus a good engaging story, all the cg in the world won't help.\",\n",
       "  0]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data preview\n",
    "train_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = d2l.get_vocab_imdb(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mxnet.contrib.text.vocab.Vocabulary at 0x7fbb249f1050>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = gdata.DataLoader(gdata.ArrayDataset(\n",
    "    *d2l.preprocess_imdb(train_data, vocab)), batch_size, shuffle = True)\n",
    "test_iter = gdata.DataLoader(gdata.ArrayDataset(\n",
    "    *d2l.preprocess_imdb(test_data, vocab)), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Block):\n",
    "    def __init__(self, vocab, embed_size, kernel_sizes, num_channels,\n",
    "                     **kwargs):\n",
    "        super(TextCNN, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(len(vocab), embed_size)\n",
    "        # 不参与训练的嵌入层\n",
    "        self.constant_embedding = nn.Embedding(len(vocab),embed_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.decoder = nn.Dense(2)\n",
    "        # 时序最大池化层没有权重， 所以可以共用一个实例\n",
    "        self.pool = nn.GlobalMaxPool1D()\n",
    "        self.convs = nn.Sequential() # 创建多个一维卷积层\n",
    "        for c,k in zip(num_channels, kernel_sizes):\n",
    "            self.convs.add(nn.Conv1D(c,k,activation='relu'))\n",
    "            \n",
    "    def forward(self, inputs):\n",
    "        # 将两个形状是（批量大小，词数，词向量维度）的嵌入层的输出按词向量连接\n",
    "        embeddings = nd.concat(\n",
    "            self.embedding(inputs), self.constant_embedding(inputs),dim=2)\n",
    "        # 根据Conv1D要求的输入格式，将词向量维，即一维卷积层的通道维，变换到前一维\n",
    "        embeddings = embeddings.transpose((0,2,1))\n",
    "        # 对于每一个一维卷积层， 在时许最大池化后会得到一个形状为（批量大小，通道大小，1）的\n",
    "        # NDArray。使用flatten函数去掉最后一维，然后再通道维上连接\n",
    "        encoding = nd.concat(*[nd.flatten(\n",
    "            self.pool(conv(embeddings))) for conv in self.convs], dim=1)\n",
    "        # 应用dropout后使用全连接层得到输出\n",
    "        outputs = self.decoder(self.dropout(encoding))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建一个TextCNN实例。它有3个卷积层，它们的核宽分别为3、4、5，输出通道数均为100。\n",
    "embed_size, kernel_sizes, num_channels = 100, [3,4,5], [100,100,100]\n",
    "ctx = d2l.try_all_gpus()\n",
    "net = TextCNN(vocab, embed_size, kernel_sizes, num_channels)\n",
    "net.initialize(init.Xavier(), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['glove', 'fasttext'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.embedding.get_pretrained_file_names().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glove.42B.300d.txt',\n",
       " 'glove.6B.50d.txt',\n",
       " 'glove.6B.100d.txt',\n",
       " 'glove.6B.200d.txt',\n",
       " 'glove.6B.300d.txt',\n",
       " 'glove.840B.300d.txt',\n",
       " 'glove.twitter.27B.25d.txt',\n",
       " 'glove.twitter.27B.50d.txt',\n",
       " 'glove.twitter.27B.100d.txt',\n",
       " 'glove.twitter.27B.200d.txt']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.embedding.get_pretrained_file_names('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 加载预训练的词向量\n",
    "glove_embedding = text.embedding.create(\n",
    "    'glove',pretrained_file_name= 'glove.6B.100d.txt',vocabulary=vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.embedding.weight.set_data(glove_embedding.idx_to_vec)\n",
    "net.constant_embedding.weight.set_data(glove_embedding.idx_to_vec)\n",
    "net.constant_embedding.collect_params().setattr('grad_req','null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on [cpu(0)]\n",
      "epoch 1, loss 0.5715, train acc 0.726, test acc 0.827, time 456.1 sec\n",
      "epoch 2, loss 0.3593, train acc 0.841, test acc 0.854, time 431.7 sec\n",
      "epoch 3, loss 0.2631, train acc 0.893, test acc 0.860, time 435.3 sec\n"
     ]
    }
   ],
   "source": [
    "# 2. 训练模型\n",
    "lr, num_epochs = 0.001, 5\n",
    "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': lr})\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "d2l.train(train_iter, test_iter, net, loss, trainer, ctx, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
